{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Multimodel AI application with LangChain and OpenAI API\n",
    "## Content\n",
    "1. Goals\n",
    "2. Setting up\n",
    "3. Download the Youtube Video\n",
    "4. Transcribe the video using Whisper\n",
    "5. Creating an In-Memory Vector Store\n",
    "6. Create the Document Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Phiên âm nội dung video Youtube bằng AI, chuyển giọng nói thành văn bản dạng Whisper\n",
    "- Sau đó sử dụng GPT để hỏi về nội dung video\n",
    "- Thực hành với thư viện LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain yt_dlp tiktoken docarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import openai\n",
    "import yt_dlp as youtube_dl\n",
    "from yt_dlp import DownloadError\n",
    "import docarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Download the Youtube Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sau khi setup, chúng ta tải về một video youtube và convert nó sang một file audio (.mp3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_url = \"https://www.youtube.com/watch?v=M53H-zwHNxs\"\n",
    "output_dir = \"./files_audio\"\n",
    "\n",
    "# config for youtube-dl\n",
    "ydl_config = {\n",
    "    \"format\": \"bestaudio/best\",\n",
    "    \"postprocessors\": [{\n",
    "        \"key\": \"FFmpegExtractAudio\",\n",
    "        \"preferredcodec\": \"mp3\",\n",
    "        \"preferredquality\": \"192\",\n",
    "    }],\n",
    "    \"outtmlp\": os.path.join(output_dir, \"%(title)s.%(ext)s\"),\n",
    "    \"verbose\": True,\n",
    "}\n",
    "\n",
    "# check if the output directory exists, if not => create\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "print(f\"Downloading video from {youtube_url}\")\n",
    "\n",
    "# download video from youtube, if download error occurs then attempt again\n",
    "try:\n",
    "    with youtube_dl.YoutubeDL(ydl_config) as ydl:\n",
    "        ydl.download([youtube_url])\n",
    "except DownloadError as e:\n",
    "    # with youtube_dl.YoutubeDL(ydl_config) as ydl:\n",
    "    #     ydl.download([youtube_url])\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = glob.glob(os.path.join(output_dir, \"*.mp3\"))\n",
    "audio_file_name = audio_file[0]\n",
    "print(audio_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Transcribe the video using Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = audio_file_name\n",
    "output_file = \"files/transcipts/transcripts.txt\"\n",
    "model = \"whisper-1\"\n",
    "\n",
    "# Transcribe the audio file to text using OpenAI API\n",
    "print(\"Converting audio to text...\")\n",
    "\n",
    "with open(audio_file, \"rb\") as audio:\n",
    "    response = openai.Audio.transcribe(model, audio)\n",
    "\n",
    "# Extract the transcript from the response\n",
    "transcript = (response['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if output_file is not None:\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "    with open(output_file, 'w') as file:\n",
    "        file.write(transcript)\n",
    "\n",
    "print(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"./files/transcripts/transcript.txt\")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Creating an In-Memory Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Create the Document Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from langchain.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DocArrayInMemorySearch.from_documents(docs, OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the DocArrayInMemorySearch instance to a retriever\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "# create a new ChatOpenAI instance with a temperature of 0.0\n",
    "llm = ChatOpenAI(temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new RetrievalQA instance with the specified parameters\n",
    "qa_stuff = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Create the Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the questions to ask the model complete the following steps:\n",
    "- Create a variable cal query and assigned it a string value of \"What is this tutorial about?\"\n",
    "- Create a response variable that will store the result of qa_stuff.run(query)\n",
    "- Show the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the query to be used for QA system\n",
    "query = \"What is this tutorial about?\"\n",
    "\n",
    "# Run the query through the RetrievalQA instance and store the response\n",
    "response = qa_stuff.run(query)\n",
    "\n",
    "# Print the response\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the query to be used for QA system\n",
    "query = \"Any question you want to ask\"\n",
    "\n",
    "# Run the query through the RetrievalQA instance and store the response\n",
    "response = qa_stuff.run(query)\n",
    "\n",
    "# Print the response\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
