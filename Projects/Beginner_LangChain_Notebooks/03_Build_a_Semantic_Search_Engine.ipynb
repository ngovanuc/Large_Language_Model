{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a semantic search engine\n",
    "\n",
    "Làm quen với document loader, embedding, vector store\n",
    "\n",
    "## Content\n",
    "1. Setup\n",
    "2. LangSmith\n",
    "3. Documents and Document Loaders\n",
    "4. Loading documents\n",
    "5. Splitting\n",
    "6. Embeddings\n",
    "7. Vector storess\n",
    "8. Usage\n",
    "9. Retrievers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    retrieval of data-- from (vector) databases and other sources\n",
    "\n",
    "Ở đây chúng ta sẽ xây dựng một công cụ tìm kiếm trên một tài liệu PDF. Điều này sẽ cho phép chúng ta tìm kiếm các đoạn văn trong PDF tương tự như truy vấn đầu vào.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain-community pypdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. LangSmith"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong một hệ thống phức tạp chứa các bước gọi LLM, khi sự phức tạp ngày càng tăng, việc có thể kiểm tra chính xác hoặc tác nhân trở nên quan trọng hơn bao giờ hết. Cách tốt nhất để giám sát quá trình là sử dụng LangSmith.\n",
    "\n",
    "- b1: truy cập https://smith.langchain.com/ (tạo tài khoản nếu cần thiết)\n",
    "- b2: setup một trình giám sát tracing (set up tracing)\n",
    "- b3: tạo api key tracing theo hướng dẫn và lưu nó\n",
    "- b4: thiết lập biến môi trường cho các key api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For tracing\n",
    "# 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"                        \n",
    "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Documents and Document Loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain triển khai lớp trừu tượng Document để biểu diễn đơn vị văn bản và các metadata liên quan. Có 3 thuộc tính chính:\n",
    "- page_content: Một chuỗi biểu diễn nội dung\n",
    "- metadata: một dict chứa metadata tùy ý\n",
    "- id (tùy chọn): Một chuỗi định dạng cho tài liệu\n",
    "\n",
    "Chúng ta cũng có thể tạo Document ngay lập tức"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"Dogs are great companions, known for their loyalty and friendliness.\",\n",
    "        metadata={\"source\": \"mammal-pets-doc\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Cats are independent pets that often enjoy their own space.\",\n",
    "        metadata={\"source\": \"mammal-pets-doc\"}\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Loading documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuy nhiên chúng ta cũng có thể sử dụng các PDF loader trong các hệ thống của chúng ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Datasets/Example_pdf_dataset\\\\2404.10981v2.pdf',\n",
       " '../Datasets/Example_pdf_dataset\\\\2405.10098v1.pdf',\n",
       " '../Datasets/Example_pdf_dataset\\\\2405.13019v2.pdf',\n",
       " '../Datasets/Example_pdf_dataset\\\\2408.12599v1.pdf']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_path = \"../Datasets/Example_pdf_dataset/*\"\n",
    "list_pdf = glob.glob(folder_path)\n",
    "list_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "loader = PyPDFLoader(list_pdf[0])\n",
    "docs = loader.load()\n",
    "print(len(docs)) # Number of pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xem thêm tài liệu về PDF loader tại đây:\n",
    "\n",
    "    https://python.langchain.com/docs/how_to/document_loader_pdf/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Survey of Retrieval-Augmented Text Generation in Large\n",
      "Language Models\n",
      "YIZHENG HUANG and JIMMY X. HUANG, York University, Canada\n",
      "Retrieval-Augmented Generation (RAG) merges retrieval methods with \n",
      "\n",
      "{'producer': 'pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'creator': 'LaTeX with acmart 2024/05/27 v2.08 Typesetting articles for the Association for Computing Machinery and hyperref 2023-04-22 v7.00x Hypertext links for LaTeX', 'creationdate': '2024-08-26T00:10:51+00:00', 'moddate': '2024-08-26T00:10:51+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '-  Computing methodologies  ->  Natural language generation.-  Information systems  ->  Information retrieval.', 'title': 'The Survey of Retrieval-Augmented Text Generation in Large Language Models', 'trapped': '/False', 'source': '../Datasets/Example_pdf_dataset\\\\2404.10981v2.pdf', 'total_pages': 37, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "# The string content of the page;\n",
    "# Metadata containing the file name and page number.\n",
    "print(f\"{docs[0].page_content[:200]}\\n\")\n",
    "print(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đối với các tác vụ thực hiện truy xuất dữ liệu và trả về câu hỏi cuối cùng, 1 trang sẽ không mang lại nhiều ý nghĩa. Mục tiêu cuối cùng của chúng ta là trích xuất các đối tượng và trả lời câu hỏi đầu vào, và việc chia nhỏ PDF hơn nữa sẽ giúp đảm bảo rằng ý nghĩa của các phần có liên quan trong tài liệu không bị \"làm mờ\" bởi văn bản xung quanh.\n",
    "\n",
    "Chúng ta sẽ chia văn bản thành các phần với 1000 ký tự và 200 ký tự chồng chéo ở mỗi phần (tức là 200 ký tự chồng đó là phần cuồi của phần trước và là phần đầu của phần sau, 2 phần liền kề sẽ chung một phần chồng chéo 200 ký tự đó)\n",
    "\n",
    "    Xem thêm hướng dẫn tại đây, bao gồm cả việc trích xuất văn bản từ hình ảnh: https://python.langchain.com/docs/how_to/document_loader_pdf/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    add_start_index=True # Chúng ta có thể chỉ định vị trí start\n",
    ")\n",
    "\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "print(len(all_splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tìm kiếm vectơ là một cách phổ biến để lưu trữ và tìm kiếm trên dữ liệu phi cấu trúc (chẳng hạn như văn bản phi cấu trúc). Ý tưởng là lưu trữ các vectơ số được liên kết với văn bản. Với một truy vấn, chúng ta có thể nhúng nó dưới dạng một vectơ có cùng chiều và sử dụng các số liệu về độ tương tự vectơ (chẳng hạn như độ tương tự cosin) để xác định văn bản liên quan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"llama3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_0 = embeddings.embed_query(all_splits[0].page_content)\n",
    "vector_1 = embeddings.embed_query(all_splits[1].page_content)\n",
    "\n",
    "assert len(vector_0) == len(vector_1)\n",
    "print(f'Generated vectors of length {len(vector_0)}\\n')\n",
    "print(vector_0[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Văn bản được các mô hình embedding biểu diễn thành các vector, sau đó chúng ta lưu trữ các vector này vào một cấu trúc dữ liệu đặc biệt hỗ trợ tìm kiếm similarity hiệu quả.\n",
    "\n",
    "=> Vector store ra đời!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Vector storess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Có nhiều nhà cung cấp kho lưu trữ vector database, trong dự án này sử dụng qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "client = QdrantClient(\":memory:\")\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name='test',\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sau khi khởi tạo vector database, chúng ta có thể lập chỉ mục cho các tài liệu\n",
    "ids = vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nhúng thường biểu diễn văn bản dưới dạng một vectơ \"dày đặc\" sao cho các văn bản có ý nghĩa tương tự gần nhau về mặt hình học. Điều này cho phép chúng ta lấy thông tin có liên quan chỉ bằng cách đưa vào một câu hỏi, mà không cần biết bất kỳ thuật ngữ khóa cụ thể nào được sử dụng trong tài liệu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return documents based on similarity to a string query:\n",
    "results = vector_store.similarity_search(\n",
    "    \"How many distribution centers does Nike have in the US?\"\n",
    ")\n",
    "print(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Async query\n",
    "results = await vector_store.asimilarity_search(\"When was Nike incorporated?\")\n",
    "print(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return scores\n",
    "# Note that providers implement different scores; the score here\n",
    "# is a distance metric that varies inversely with similarity.\n",
    "\n",
    "results = vector_store.similarity_search_with_score(\"What was Nike's revenue in 2023?\")\n",
    "doc, score = results[0]\n",
    "print(f\"Score: {score}\\n\")\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "@chain\n",
    "def retriever(query: str) -> List[Document]:\n",
    "    return vector_store.similarity_search(query, k=1)\n",
    "\n",
    "retriever.batch(\n",
    "    [\n",
    "        \"How many distribution centers does Nike have in the US?\",\n",
    "        \"When was Nike incorporated?\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "phương thức as_retriever sẽ tạo ra một Retriever, cụ thể là một VectorStoreRetriever. Các retriever này bao gồm các thuộc tính search_type và search_kwargs cụ thể để xác định phương thức nào của vector store cơ bản cần gọi và cách tham số hóa chúng. Ví dụ, chúng ta có thể sao chép nội dung trên bằng cách sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 1},\n",
    ")\n",
    "\n",
    "retriever.batch(\n",
    "    [\n",
    "        \"How many distribution centers does Nike have in the US?\",\n",
    "        \"When was Nike incorporated?\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VectorStoreRetriever hỗ trợ các loại tìm kiếm \"similarity\" (mặc định), \"mmr\" (mức độ liên quan tối đa, được mô tả ở trên) và \"similarity_score_threshold\". Chúng ta có thể sử dụng loại sau để ngưỡng các tài liệu đầu ra của trình thu thập theo điểm tương đồng. Trình thu thập có thể dễ dàng được tích hợp vào các ứng dụng phức tạp hơn, chẳng hạn như các ứng dụng tạo tăng cường thu thập (RAG) kết hợp một câu hỏi nhất định với ngữ cảnh đã thu thập thành lời nhắc cho LLM. Để tìm hiểu thêm về cách xây dựng ứng dụng như vậy, hãy xem hướng dẫn RAG. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
