{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building AI Assistants with GPT model\n",
    "## Content\n",
    "1. Before you start\n",
    "2. Setup\n",
    "3. Upload the papers\n",
    "4. Add the file to a vector Store\n",
    "5. Create the assistant\n",
    "6. Take a conversation thread\n",
    "7. Run the Assistant\n",
    "8. Add another Message and Run it again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Before you start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- đảm bảo có một APENAI_API_KEY và có credit trong tài khoản"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from openai import Client\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = 'INSERT_YOUR_OPEN_API_KEY'\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Upload the papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put pdf file into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file_for_assistant(file_path):\n",
    "    uploaded_file = client.files.create(\n",
    "        file=open(file_path, 'tb'),\n",
    "        purpose='assistants'\n",
    "    )\n",
    "    return uploaded_file.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = pd.DataFrame()\n",
    "\n",
    "# Assign to uploaded_file_ids\n",
    "uploaded_file_ids = papers['filename'].apply(upload_file_for_assistant).to_list()\n",
    "\n",
    "# See the result\n",
    "uploaded_file_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Add the file to a vector Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access the documents and get sensible results, they need to be split up into small chunks and added to a vector database.\n",
    "\n",
    "The assistants API lets you avoid worrying about the chunking stage, so you just need to specify the file IDs that you want to add to a vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vstore = client.beta.vector_stores.create(\n",
    "        file_ids=uploaded_file_ids,\n",
    "        name='vector store name',\n",
    ")\n",
    "vstore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Create the assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The assistant need a prompt describing how it should behave. This consists of a few paragraphs of text that give gpt information about what its role is, what it shoukd be talking about and how to phrases the responses\n",
    "\n",
    "    Pro tip:\n",
    "\n",
    "Just like any other writing, assistant prompt can be generated using chatGPT (of any LLM). The prompt below was draffted by ChatGPT and ha only minor human editing. Here is the ChatGPT promt I used to create the assistant prompt:\n",
    "\n",
    "    I'm going to make a GPT assistant that explains the content of journal aricles about artificial general intelligence. The assistant, named \"Aggie\", must be able to read arxiv papers in PDF form, and explain the contents of those papers to an audience of data scientist. Please suggest a good instruction prompt for the AI assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_prompt = \"\"\"Instruction for Aggie - The AGI Paper Explainer\n",
    "\n",
    "Role:\n",
    "You are Aggie, an expert AI assistant specialized in analyzing and explaining research papers on Artificial General Intelligence (AGI). Your primary audience consists of data scientists who are proficient in AI and machine learning but may not have expertise in every theoretical or mathematical aspect of AGI research.\n",
    "\n",
    "Capabilities:\n",
    "\n",
    "Read and process PDF files of academic papers from arXiv.\n",
    "Extract key ideas, methodologies, results, and implications from these papers.\n",
    "Summarize content in a structured and digestible manner.\n",
    "Provide technical explanations with clarity, focusing on what is important for data scientists.\n",
    "Simplify complex mathematical or theoretical concepts without losing depth.\n",
    "Compare findings with previous research when relevant.\n",
    "Identify potential real-world applications or limitations of the research.\n",
    "Answer follow-up questions and clarify specific sections of the paper as requested.\n",
    "Output Style:\n",
    "\n",
    "Use a structured format: Title, Authors, Abstract Summary, Key Contributions, Methodology, Results, Discussion, and Implications.\n",
    "Keep summaries concise yet detailed enough for data scientists to grasp key insights.\n",
    "When necessary, include diagrams or pseudocode to enhance understanding.\n",
    "Use professional but approachable language—technical yet not overly academic.\n",
    "If a topic is highly theoretical, provide intuitive analogies where appropriate.\n",
    "Examples of Requests You Handle:\n",
    "\n",
    "\"Summarize this AGI paper in 500 words.\"\n",
    "\"Explain the methodology in layman's terms but with technical accuracy.\"\n",
    "\"Compare this paper's findings with DeepMind's latest work on AGI.\"\n",
    "\"Does this paper propose a practical implementation, or is it purely theoretical?\"\n",
    "Additional Constraints:\n",
    "\n",
    "Always ensure factual accuracy and avoid over-simplifications that may mislead.\n",
    "Be neutral and objective—do not exaggerate claims or assume a paper’s conclusions are definitive unless clearly stated by the authors.\n",
    "If an arXiv paper has known critiques or debates surrounding it, briefly mention them.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the assistant: assign to Aggie\n",
    "- Call it \"Aggie\" (or anothor memorable name)\n",
    "- Give it the assistant_prompt\n",
    "- Set the model to use, gpt-4o\n",
    "- Give it access to the file search tool\n",
    "- Give it access to the vector store resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the assistant. Assign to Aggie\n",
    "aggie = client.beta.assistants.create(\n",
    "    name='Aggie',\n",
    "    instructions=assistant_prompt,\n",
    "    model='gpt-4o',\n",
    "    tools=[{'type': 'file_research'}],\n",
    "    tool_resources={'file_search': {'vector_store_ids': [vstore.id]}}\n",
    ")\n",
    "\n",
    "# See the result\n",
    "aggie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the assistants in your account at OpenAI platform!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Take a conversation thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = client.beta.threads.create()\n",
    "\n",
    "conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a user message to the conversation. Assign to msg_what_is_agi\n",
    "- Give it the thread id\n",
    "- Make it a user message\n",
    "- Ask \"What are the most common definitions of AGI?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_what_is_agi = client.beta.threads.messages.create(\n",
    "    thread_id=conversation.id,\n",
    "    role='user',\n",
    "    content=\"What are the most common definitions of AGI?\"\n",
    ")\n",
    "\n",
    "# See the result\n",
    "msg_what_is_agi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Run the Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the code to define an event handler\n",
    "from typing_extensions import override\n",
    "from openai import AssistantEventHandler\n",
    "\n",
    "\n",
    "class EventHandler(AssistantEventHandler):\n",
    "    @override\n",
    "    def on_text_created(self, text) -> None:\n",
    "        print(f'assistant > ', end='', flus=True)\n",
    "\n",
    "    @override\n",
    "    def on_text_delta(self, delta, snapshot):\n",
    "        print(delta.value, end='', flush=True)\n",
    "\n",
    "    def on_tool_call_created(self, delta, snapshot):\n",
    "        if delta.type == 'code_interpreter':\n",
    "            if delta.code_interpreter.input:\n",
    "                print(delta.code_interpreter.input, end='', flush=True)\n",
    "            if delta.code_interpreter.outputs:\n",
    "                print(f'output > ', flush=True)\n",
    "                for output in delta.code_interpreter.outputs:\n",
    "                    if output.type == 'log':\n",
    "                        print(f'{output.logs}', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finnaly we are ready to run the assistant to get it to answer out question. The code is the same every time, so we can wrap it in a function.\n",
    "\n",
    "Streaming responses mean that text displayed a few word at a time, rather then waiting for the entirety of the text to be generated and printing all at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_aggie():\n",
    "    with client.beta.thread.runs.stream(\n",
    "        thread_id=conversation.id,\n",
    "        assistant_id=aggie.id,\n",
    "        event_handler=EventHandler(),\n",
    "    ) as stream:\n",
    "        stream.until_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_aggie()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Add another Message and Run it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create another user message, adding it to the conversation. Assign to msg_how_close_agi\n",
    "msg_how_close_agi = client.beta.threads.messages.create(\n",
    "    thread_id=conversation.id,\n",
    "    role='user',\n",
    "    content=\"How close are we to deploying AGI?\"\n",
    ")\n",
    "\n",
    "msg_how_close_agi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_aggie()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
