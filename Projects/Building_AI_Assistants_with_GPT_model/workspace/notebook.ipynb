{"cells":[{"source":"# Code-along | 2024-06-11 | Creating AI Assistants with GPT-4o | Richie Cotton","metadata":{},"cell_type":"markdown","id":"d239c107-6848-4445-8166-e759bf7f8736"},{"source":"Create a GPT-4o file search assistant that summarizes and explains arxiv papers about AGI.\n\nThe flow of this session is largely taken from the DataCamp [OpenAI Assistants API Tutorial](https://www.datacamp.com/tutorial/open-ai-assistants-api-tutorial) and the [OpenAI Assistants API documentation](https://platform.openai.com/docs/assistants/overview).","metadata":{},"cell_type":"markdown","id":"27405eab-76ef-4d8e-8b28-5f3322983267"},{"source":"#### Notes\n\n- OpenAI considers this much of this code experimental, so expect some changes in the coming months.","metadata":{},"cell_type":"markdown","id":"4c85cd05-9145-4084-90e2-8c8ccddebffd"},{"source":"## Before you begin","metadata":{},"cell_type":"markdown","id":"8f62cfca-cf71-4321-bf20-00821a794ab1"},{"source":"- Make sure you have an OpenAI developer account.\n- Your OpenAI developer account has credit on it.\n- Define an environment variable named `OPENAI_API_KEY` containing the API key.","metadata":{},"cell_type":"markdown","id":"6109159e-4ba7-4d17-abaf-ba8104ae75bd"},{"source":"## Task 0: Setup","metadata":{},"cell_type":"markdown","id":"06958f03-f502-43cb-b0af-139f05b00ef7"},{"source":"First we need to make sure that we are using the latest version of the OpenAI API package.","metadata":{},"cell_type":"markdown","id":"3373f8ac-ba32-4463-b6a5-66f008d8406d"},{"source":"# Run this to install the latest version of the OpenAI package\n!pip install openai==1.33.0","metadata":{"executionCancelledAt":null,"executionTime":7344,"lastExecutedAt":1718113582649,"lastExecutedByKernel":"c8505c18-120c-427b-bbc3-1c142740848a","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Run this to install the latest version of the OpenAI package\n!pip install openai==1.33.0","outputsMetadata":{"0":{"height":521,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"cell_type":"code","id":"e54fd213-2621-42ae-94ae-bfd0f3402230","outputs":[],"execution_count":1},{"source":"We need the `os`, `openai`, and `pandas` packages.","metadata":{},"cell_type":"markdown","id":"acaa9eb2-3622-47a8-98b9-17c8a6ba5af3"},{"source":"### Instructions\n\n- Import the `os` and `openai` packages without an alias.\n- Import the `pandas` package with its usual alias.","metadata":{},"cell_type":"markdown","id":"4f518ced-a5ef-4cdb-bcf8-01c08868ca35"},{"source":"# Import the os package\n\n\n# Import the openai package\n\n\n# Import the pandas package with an alias\n","metadata":{"executionCancelledAt":null,"executionTime":2055,"lastExecutedAt":1718113584706,"lastExecutedByKernel":"c8505c18-120c-427b-bbc3-1c142740848a","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import the os package\nimport os\n\n# Import the openai package\nimport openai\n\n# Import the pandas package with an alias\nimport pandas as pd"},"cell_type":"code","id":"c4800650-5f9d-4cc8-a3a4-f5a81e53ef44","outputs":[],"execution_count":2},{"source":"We need to define an OpenAI client.","metadata":{},"cell_type":"markdown","id":"a9e61cbc-6367-4a2d-9bcc-ef4a64e6de25"},{"source":"### Instructions\n\n- Define an OpenAI client. Assign to `client`.","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false}},"cell_type":"markdown","id":"df61d8ab-7fb3-403e-b071-228b8b9644b5"},{"source":"# Define an OpenAI client. Assign to client.\n","metadata":{"executionCancelledAt":null,"executionTime":53,"lastExecutedAt":1718113584761,"lastExecutedByKernel":"c8505c18-120c-427b-bbc3-1c142740848a","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define an OpenAI client. Assign to client.\nclient = openai.OpenAI()"},"cell_type":"code","id":"2bdb5463-7586-4fec-bb70-d3527524d779","outputs":[],"execution_count":3},{"source":"## Task 1: Upload the Papers","metadata":{},"cell_type":"markdown","id":"712c314c-24d4-4af8-b678-7697dac54ae3"},{"source":"So that GPT knows about the latest AGI research, we will provide it with some arxiv papers. There are 10 recent papers on AGI stored in the `papers` directory of this workbook.\n\n_Click File -> Show workbook files to see a file browser._\n\n_The papers were found by searching arxiv for \"AGI\", then eyballing recent papers for content on definitions of AGI or progress towards AGI._\n\nThe table below shows the filenames and the titles of the papers.","metadata":{},"cell_type":"markdown","id":"b4295745-4a70-4496-8d84-3472f9519fda"},{"source":"# Run this\npapers = pd.DataFrame({\n    \"filename\": [\n        \"2405.10313v1.pdf\",\n        \"2401.03428v1.pdf\",\n        \"2401.09395v2.pdf\",\n        \"2401.13142v3.pdf\",\n        \"2403.02164v2.pdf\",\n        \"2403.12107v1.pdf\",\n        \"2404.10731v1.pdf\",\n        \"2312.11562v5.pdf\",\n        \"2311.02462v2.pdf\",\n        \"2310.15274v1.pdf\"\n    ],\n    \"title\": [\n        \"How Far Are We From AGI?\",\n        \"EXPLORING LARGE LANGUAGE MODEL BASED INTELLIGENT AGENTS: DEFINITIONS, METHODS, AND PROSPECTS\",\n        \"CAUGHT IN THE QUICKSAND OF REASONING, FAR FROM AGI SUMMIT: Evaluating LLMs’ Mathematical and Coding Competency through Ontology-guided Interventions\",\n        \"Unsocial Intelligence: an Investigation of the Assumptions of AGI Discourse\",\n        \"Cognition is All You Need The Next Layer of AI Above Large Language Models\",\n        \"Scenarios for the Transition to AGI\",\n        \"What is Meant by AGI? On the Definition of Artificial General Intelligence\",\n        \"A Survey of Reasoning with Foundation Models\",\n        \"Levels of AGI: Operationalizing Progress on the Path to AGI\",\n        \"Systematic AI Approach for AGI: Addressing Alignment, Energy, and AGI Grand Challenges\"\n    ]\n})\npapers[\"filename\"] = \"papers/\" + papers[\"filename\"]\npapers","metadata":{"executionCancelledAt":null,"executionTime":53,"lastExecutedAt":1718113584815,"lastExecutedByKernel":"c8505c18-120c-427b-bbc3-1c142740848a","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Run this\npapers = pd.DataFrame({\n    \"filename\": [\n        \"2405.10313v1.pdf\",\n        \"2401.03428v1.pdf\",\n        \"2401.09395v2.pdf\",\n        \"2401.13142v3.pdf\",\n        \"2403.02164v2.pdf\",\n        \"2403.12107v1.pdf\",\n        \"2404.10731v1.pdf\",\n        \"2312.11562v5.pdf\",\n        \"2311.02462v2.pdf\",\n        \"2310.15274v1.pdf\"\n    ],\n    \"title\": [\n        \"How Far Are We From AGI?\",\n        \"EXPLORING LARGE LANGUAGE MODEL BASED INTELLIGENT AGENTS: DEFINITIONS, METHODS, AND PROSPECTS\",\n        \"CAUGHT IN THE QUICKSAND OF REASONING, FAR FROM AGI SUMMIT: Evaluating LLMs’ Mathematical and Coding Competency through Ontology-guided Interventions\",\n        \"Unsocial Intelligence: an Investigation of the Assumptions of AGI Discourse\",\n        \"Cognition is All You Need The Next Layer of AI Above Large Language Models\",\n        \"Scenarios for the Transition to AGI\",\n        \"What is Meant by AGI? On the Definition of Artificial General Intelligence\",\n        \"A Survey of Reasoning with Foundation Models\",\n        \"Levels of AGI: Operationalizing Progress on the Path to AGI\",\n        \"Systematic AI Approach for AGI: Addressing Alignment, Energy, and AGI Grand Challenges\"\n    ]\n})\npapers[\"filename\"] = \"papers/\" + papers[\"filename\"]\npapers","outputsMetadata":{"0":{"height":318,"type":"dataFrame"}},"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":true}},"cell_type":"code","id":"5591f007-4b68-4b2a-ab00-4289b2b498cf","outputs":[],"execution_count":4},{"source":"To upload a file, you use `open()` to open it to get a file handle, then pass that handle to the client's `.files.create()` method. This returns details of the uploaded file, and the part we need to reuse is the file ID.\n\nThe code is the same every time, so we can simply use this standard function, created by DataCamp author Zoumana Keita.","metadata":{},"cell_type":"markdown","id":"4997a841-fe9f-484e-abe7-c66e26debf67"},{"source":"### Instructions\n\n- Run this code to define a function to upload a file to the assistant.","metadata":{},"cell_type":"markdown","id":"8faba94a-14d8-4b40-b561-84b999206d8b"},{"source":"# Run this\ndef upload_file_for_assistant(file_path): \n    uploaded_file = client.files.create(\n        file=open(file_path, \"rb\"),\n        purpose='assistants'\n    )\n    return uploaded_file.id","metadata":{"executionCancelledAt":null,"executionTime":47,"lastExecutedAt":1718113584862,"lastExecutedByKernel":"c8505c18-120c-427b-bbc3-1c142740848a","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Run this\ndef upload_file_for_assistant(file_path): \n    uploaded_file = client.files.create(\n        file=open(file_path, \"rb\"),\n        purpose='assistants'\n    )\n    return uploaded_file.id"},"cell_type":"code","id":"98bcae6e-3f54-4d0a-90ee-b33c1fd0894e","outputs":[],"execution_count":5},{"source":"Now we apply the `upload_file_for_assistant()` function to each filename in the papers dataset to upload them.","metadata":{},"cell_type":"markdown","id":"8eb0dfed-71b6-4262-88a9-2a60cf33e5ae"},{"source":"### Instructions\n\n- In `papers`, select the `filename` column, then apply `upload_file_for_assistant()`, then convert the result to a list. Assign to `uploaded_file_ids`.","metadata":{},"cell_type":"markdown","id":"3e711b2a-4893-4343-b5b3-1129cb8980a6"},{"source":"# In papers, select the filename column, \n# then apply upload_file_for_assistant(),\n# then convert the result to a list. \n# Assign to uploaded_file_ids.\n\n\n# See the result\nuploaded_file_ids","metadata":{"executionCancelledAt":null,"executionTime":11878,"lastExecutedAt":1718113596740,"lastExecutedByKernel":"c8505c18-120c-427b-bbc3-1c142740848a","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# In papers, select the filename column, \n# then apply upload_file_for_assistant(),\n# then convert the result to a list. \n# Assign to uploaded_file_ids.\nuploaded_file_ids = papers[\"filename\"] \\\n    .apply(upload_file_for_assistant) \\\n    .to_list()\n\n# See the result\nuploaded_file_ids","collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"cell_type":"code","id":"9d23ffbc-e8dc-4d84-8255-08b55da66270","outputs":[],"execution_count":6},{"source":"### Check that this worked\n\nView the files in your account at https://platform.openai.com/storage/files","metadata":{},"cell_type":"markdown","id":"3d5dcf62-5677-4a95-bf43-48ab0ee7fdc9"},{"source":"## Task 2: Add the Files to a Vector Store","metadata":{},"cell_type":"markdown","id":"7c3e7127-c030-46ed-8226-9662af92198e"},{"source":"To access the documents and get sensible results, they need to be split up into small chunks and added to a vector database.\n\nThe assistants API lets you avoid worrying about the chunking stage, so you just need to specify the file IDs that you want to add to a vector database.","metadata":{},"cell_type":"markdown","id":"97737898-14ef-4e20-8b9e-b77d63c0e941"},{"source":"#### Notes\n\n- You will get charged daily for having a vector database. By default, it will automatically be deleted after 7 days of not being used, but I suggest deleting it straight after this code-along if you don't want to be charged for a week.","metadata":{},"cell_type":"markdown","id":"46f37c72-dfd8-459f-a190-7a5d4d03765a"},{"source":"### Instructions\n\n- Create a vector store, associating the uploaded file IDs and naming it. (Suggested name: `arxiv_agi_papers`.) Assign to `vstore`.","metadata":{},"cell_type":"markdown","id":"2a891dae-6bc3-4667-a561-62acffa26d71"},{"source":"<details>\n  <summary>Code hints</summary>\n  <p>\n\nThe code pattern for giving a vector store resource to a file search tool is as follows.\n        \n```py\nvstore = client.beta.vector_stores.create(\n    file_ids = file_ids,\n    name = \"vector store name\"\n)\n```\n        \n  </p>\n</details>   ","metadata":{},"cell_type":"markdown","id":"6e232f63-c590-447c-b7f7-40563dc455bc"},{"source":"# Create a vector store, associating the uploaded file IDs and naming it.\n\n\n# See the results\nvstore","metadata":{"executionCancelledAt":null,"executionTime":844,"lastExecutedAt":1718113597584,"lastExecutedByKernel":"c8505c18-120c-427b-bbc3-1c142740848a","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Create a vector store, associating the uploaded file IDs and naming it.\nvstore = client.beta.vector_stores.create(\n    file_ids = uploaded_file_ids,\n    name = \"arxiv_agi_papers\"\n)\n\n# See the results\nvstore"},"cell_type":"code","id":"4831a606-50c3-42be-9448-4ba44f49959a","outputs":[],"execution_count":7},{"source":"### Check that this worked\n\nView the vector stores in your account at https://platform.openai.com/storage/vector_stores","metadata":{},"cell_type":"markdown","id":"e7820b86-5729-423d-87e3-7fb8fff0bcb9"},{"source":"## Task 3: Create the Assistant","metadata":{},"cell_type":"markdown","id":"8ed36d72-f053-408b-bcbb-76b679d158a7"},{"source":"The assistant needs a prompt describing how it should behave. This consists of a few paragraphs of text that give GPT information about what its role is, what it should be talking about, and how to phrase the responses.","metadata":{},"cell_type":"markdown","id":"345d9df2-b076-4096-9600-0778d346f4cd"},{"source":"#### Pro tip\n\nJust like any other writing, assistants prompt can be generated using ChatGPT (or any LLM). The prompt below was drafted by ChatGPT and had only minor human editing.\n\nHere is the ChatGPT prompt I used to create the assistant prompt.\n\n> I'm going to make a GPT assistant that explains the contents of journal articles about artificial general intelligence. The assistant, named 'Aggie', must be able to read arxiv papers in PDF form, and and explain the contents of those papers to an audience of data scientists. Please suggest a good instruction prompt for the AI assistant.","metadata":{},"cell_type":"markdown","id":"0225a719-09f2-4d72-a65a-0acc6ae1d276"},{"source":"### Instructions\n\n- Read the assistant prompt text to get a feel for what it is doing.\n- Run the code to define the assistant prompt.","metadata":{},"cell_type":"markdown","id":"98ac693a-6bbe-466d-8aee-63dac323d10b"},{"source":"# Run this\nassistant_prompt = \"\"\"\nYou are Aggie, a knowledgeable and articulate AI assistant specializing in artificial general intelligence (AGI). Your primary role is to read and explain the contents of academic journal articles, particularly those available on arXiv in PDF form. Your target audience comprises data scientists who are familiar with AI concepts but may not be experts in AGI.\n\nWhen explaining the contents of the papers, follow these guidelines:\n\nIntroduction: Start with a brief overview of the paper's title, authors, and the main objective or research question addressed.\n\nAbstract Summary: Provide a concise summary of the abstract, highlighting the key points and findings.\n\nKey Sections and Findings: Break down the paper into its main sections (e.g., Introduction, Methods, Results, Discussion). For each section, provide a summary that includes:\n\nThe main points and arguments presented.\nAny important methods or techniques used.\nKey results and findings.\nThe significance and implications of these findings.\nConclusion: Summarize the conclusions drawn by the authors, including any limitations they mention and future research directions suggested.\n\nCritical Analysis: Offer a critical analysis of the paper, discussing its strengths and weaknesses. Highlight any innovative approaches or significant contributions to the field of AGI.\n\nContextual Understanding: Place the paper in the context of the broader field of AGI research. Mention how it relates to other work in the area and its potential impact on future research and applications.\n\nPractical Takeaways: Provide practical takeaways or insights that data scientists can apply in their work. This could include novel methodologies, interesting datasets, or potential areas for collaboration or further study.\n\nQ&A Readiness: Be prepared to answer any follow-up questions that data scientists might have about the paper, providing clear and concise explanations.\n\nEnsure that your explanations are clear, concise, and accessible, avoiding unnecessary jargon. Your goal is to make complex AGI research comprehensible and relevant to data scientists, facilitating their understanding and engagement with the latest advancements in the field.\n\"\"\"","metadata":{"executionCancelledAt":null,"executionTime":50,"lastExecutedAt":1718113597634,"lastExecutedByKernel":"c8505c18-120c-427b-bbc3-1c142740848a","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Run this\nassistant_prompt = \"\"\"\nYou are Aggie, a knowledgeable and articulate AI assistant specializing in artificial general intelligence (AGI). Your primary role is to read and explain the contents of academic journal articles, particularly those available on arXiv in PDF form. Your target audience comprises data scientists who are familiar with AI concepts but may not be experts in AGI.\n\nWhen explaining the contents of the papers, follow these guidelines:\n\nIntroduction: Start with a brief overview of the paper's title, authors, and the main objective or research question addressed.\n\nAbstract Summary: Provide a concise summary of the abstract, highlighting the key points and findings.\n\nKey Sections and Findings: Break down the paper into its main sections (e.g., Introduction, Methods, Results, Discussion). For each section, provide a summary that includes:\n\nThe main points and arguments presented.\nAny important methods or techniques used.\nKey results and findings.\nThe significance and implications of these findings.\nConclusion: Summarize the conclusions drawn by the authors, including any limitations they mention and future research directions suggested.\n\nCritical Analysis: Offer a critical analysis of the paper, discussing its strengths and weaknesses. Highlight any innovative approaches or significant contributions to the field of AGI.\n\nContextual Understanding: Place the paper in the context of the broader field of AGI research. Mention how it relates to other work in the area and its potential impact on future research and applications.\n\nPractical Takeaways: Provide practical takeaways or insights that data scientists can apply in their work. This could include novel methodologies, interesting datasets, or potential areas for collaboration or further study.\n\nQ&A Readiness: Be prepared to answer any follow-up questions that data scientists might have about the paper, providing clear and concise explanations.\n\nEnsure that your explanations are clear, concise, and accessible, avoiding unnecessary jargon. Your goal is to make complex AGI research comprehensible and relevant to data scientists, facilitating their understanding and engagement with the latest advancements in the field.\n\"\"\""},"cell_type":"code","id":"b072f6b7-7071-4db5-b38c-30281739bc36","outputs":[],"execution_count":8},{"source":"Now the assistant can be created. You simply give it a name, the prompt, the model to use (in this case GPT-4o), and specify which tools and resources it is allowed to use.","metadata":{},"cell_type":"markdown","id":"85538734-8156-4d03-8356-ca68f920f1f9"},{"source":"### Instructions\n\n- Define the assistant. Assign to `aggie`.\n    - Call it \"Aggie\" (or another memorable name).\n    - Give it the `assistant_prompt`.\n    - Set the model to use, `gpt-4o`.\n    - Give it access to the file search tool.\n    - Give it access to the vector store tool resource.","metadata":{},"cell_type":"markdown","id":"0e10468c-7449-4869-92bc-65f735cb6456"},{"source":"<details>\n  <summary>Code hints</summary>\n  <p>\n\nThe code pattern for creating a file search assistant is as follows.\n        \n```py\nassistant = client.beta.assistants.create(\n\tname = \"assistant name\",\n\tinstructions = prompt,\n\tmodel=\"gpt-4o\",\n\ttools=[{\"type\": \"file_search\"}],\n    tool_resources={\"file_search\": {\"vector_store_ids\": [vstore.id]}}\n)\n```\n        \n  </p>\n</details>   ","metadata":{},"cell_type":"markdown","id":"683bab0e-1ff6-447f-be54-32ac697d08db"},{"source":"# Define the assistant. Assign to aggie.\n\n    \n# See the result\naggie","metadata":{"executionCancelledAt":null,"executionTime":330,"lastExecutedAt":1718113597965,"lastExecutedByKernel":"c8505c18-120c-427b-bbc3-1c142740848a","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define the assistant. Assign to aggie.\naggie = client.beta.assistants.create(\n\tname = \"Aggie\",\n\tinstructions = assistant_prompt,\n\tmodel=\"gpt-4o\",\n\ttools=[{\"type\": \"file_search\"}],\n    tool_resources={\"file_search\": {\"vector_store_ids\": [vstore.id]}}\n)\n    \n# See the result\naggie"},"cell_type":"code","id":"a9da4370-6f66-4fd1-b309-5c330949d5d6","outputs":[],"execution_count":9},{"source":"### Check that this worked\n\nView the assistants in your account at https://platform.openai.com/playground/assistants","metadata":{},"cell_type":"markdown","id":"6bc73e71-f1e8-49e8-93b9-633a07ca484f"},{"source":"## Task 4: Create a Conversation Thread","metadata":{},"cell_type":"markdown","id":"9137136e-ff49-484e-90f5-c3c498363600"},{"source":"Now you have an assistant, you can have a conversation. The first step in this is to create a thread object to contain the messages.","metadata":{},"cell_type":"markdown","id":"91ecfd3d-fefe-4263-ab67-e6b8ab59ef05"},{"source":"### Instructions\n\n- Create a thread object. Assign to `conversation`.","metadata":{},"cell_type":"markdown","id":"86143937-a7cc-4834-91cd-63dfefa1fc6d"},{"source":"<details>\n  <summary>Code hints</summary>\n  <p>\n\nTo create a conversation object, call `client.beta.threads.create()`.\n        \n  </p>\n</details>  ","metadata":{},"cell_type":"markdown","id":"6b11d690-f695-40d4-9eef-e863f5b5dacb"},{"source":"# Create a thread object. Assign to conversation.\n\n\n# See the result\nconversation","metadata":{"executionCancelledAt":null,"executionTime":227,"lastExecutedAt":1718113598192,"lastExecutedByKernel":"c8505c18-120c-427b-bbc3-1c142740848a","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Create a thread object. Assign to conversation.\nconversation = client.beta.threads.create()\n\n# See the result\nconversation"},"cell_type":"code","id":"21a7227c-61bd-4124-b7ec-da82d86e8a0a","outputs":[],"execution_count":10},{"source":"Next you can add a message to the conversaation thread to ask a question.","metadata":{},"cell_type":"markdown","id":"a939e280-dfc2-45f6-88f1-57ca6e128489"},{"source":"### Instructions\n\n- Add a user message to the conversation. Assign to `msg_what_is_agi`.\n    - Give it the thread id.\n    - Make it a user message.\n    - Ask \"What are the most common definitions of AGI?\".","metadata":{},"cell_type":"markdown","id":"736ebbba-41f1-46de-8242-6aa10d8d1b56"},{"source":"<details>\n  <summary>Code hints</summary>\n  <p>\n\nThe code pattern for creating a message is as follows.\n        \n```py\nmsg = client.beta.threads.messages.create(\n    thread_id=conversation.id,\n    role=\"user\",\n    content=\"your question\"\n)\n```\n        \n  </p>\n</details>   ","metadata":{},"cell_type":"markdown","id":"b6d0adf5-dec5-4762-b8f5-541a95d48170"},{"source":"# Add a user message to the conversation. Assign to msg_what_is_agi.\n\n\n# See the result\nmsg_what_is_agi","metadata":{"executionCancelledAt":null,"executionTime":289,"lastExecutedAt":1718113598481,"lastExecutedByKernel":"c8505c18-120c-427b-bbc3-1c142740848a","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Add a user message to the conversation. Assign to msg_what_is_agi.\nmsg_what_is_agi = client.beta.threads.messages.create(\n    thread_id=conversation.id,\n    role=\"user\",\n    content=\"What are the most common definitions of AGI?\"\n)\n\n# See the results\nmsg_what_is_agi"},"cell_type":"code","id":"df4be81f-6a97-4c24-8a0d-cdf1e6724e62","outputs":[],"execution_count":11},{"source":"## Task 5: Run the assistant","metadata":{},"cell_type":"markdown","id":"62515241-431f-4c7c-9e38-7e4522553173"},{"source":"Running the assistant requires an event handler to make it print the responses. While it's fairly tricky code, you never need to change it. This code is taken verbatim from [the OpenAI assistants documentation](https://platform.openai.com/docs/assistants/overview).","metadata":{},"cell_type":"markdown","id":"652813e3-ff47-4f8b-b1db-0eca4368e67b"},{"source":"### Instructions\n\n- Run the code to define an event handler.","metadata":{},"cell_type":"markdown","id":"e968c460-9142-4f9d-b37a-e96f8d864286"},{"source":"# Run this\nfrom typing_extensions import override\nfrom openai import AssistantEventHandler\n \n# First, we create a EventHandler class to define\n# how we want to handle the events in the response stream.\n \nclass EventHandler(AssistantEventHandler):    \n  @override\n  def on_text_created(self, text) -> None:\n    print(f\"\\nassistant > \", end=\"\", flush=True)\n      \n  @override\n  def on_text_delta(self, delta, snapshot):\n    print(delta.value, end=\"\", flush=True)\n      \n  def on_tool_call_created(self, tool_call):\n    print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n  \n  def on_tool_call_delta(self, delta, snapshot):\n    if delta.type == 'code_interpreter':\n      if delta.code_interpreter.input:\n        print(delta.code_interpreter.input, end=\"\", flush=True)\n      if delta.code_interpreter.outputs:\n        print(f\"\\n\\noutput >\", flush=True)\n        for output in delta.code_interpreter.outputs:\n          if output.type == \"logs\":\n            print(f\"\\n{output.logs}\", flush=True)\n","metadata":{"executionCancelledAt":null,"executionTime":49,"lastExecutedAt":1718113598530,"lastExecutedByKernel":"c8505c18-120c-427b-bbc3-1c142740848a","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Run this\nfrom typing_extensions import override\nfrom openai import AssistantEventHandler\n \n# First, we create a EventHandler class to define\n# how we want to handle the events in the response stream.\n \nclass EventHandler(AssistantEventHandler):    \n  @override\n  def on_text_created(self, text) -> None:\n    print(f\"\\nassistant > \", end=\"\", flush=True)\n      \n  @override\n  def on_text_delta(self, delta, snapshot):\n    print(delta.value, end=\"\", flush=True)\n      \n  def on_tool_call_created(self, tool_call):\n    print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n  \n  def on_tool_call_delta(self, delta, snapshot):\n    if delta.type == 'code_interpreter':\n      if delta.code_interpreter.input:\n        print(delta.code_interpreter.input, end=\"\", flush=True)\n      if delta.code_interpreter.outputs:\n        print(f\"\\n\\noutput >\", flush=True)\n        for output in delta.code_interpreter.outputs:\n          if output.type == \"logs\":\n            print(f\"\\n{output.logs}\", flush=True)\n"},"cell_type":"code","id":"934c5d08-00db-4a55-974d-06ca5d021b18","outputs":[],"execution_count":12},{"source":"Finally, we are ready to run the assistant to get it to answer our question. The code is the same every time, so we can wrap it in a function.\n\nStreaming responses mean that text is displayed a few words at a time, rather than waiting for the entirety of the text to be generated and printing all at once.","metadata":{},"cell_type":"markdown","id":"e0be1093-858c-4806-98cb-d240d110360d"},{"source":"### Instructions\n\n- Run the code to define the function.","metadata":{},"cell_type":"markdown","id":"f540875a-1fa1-44af-9922-966aa15511fe"},{"source":"# Run this\ndef run_aggie():\n    with client.beta.threads.runs.stream(\n        thread_id=conversation.id,\n        assistant_id=aggie.id,\n        event_handler=EventHandler(),\n    ) as stream:\n        stream.until_done()","metadata":{"executionCancelledAt":null,"executionTime":56,"lastExecutedAt":1718113598587,"lastExecutedByKernel":"c8505c18-120c-427b-bbc3-1c142740848a","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Run this\ndef run_aggie():\n    with client.beta.threads.runs.stream(\n        thread_id=conversation.id,\n        assistant_id=aggie.id,\n        event_handler=EventHandler(),\n    ) as stream:\n        stream.until_done()","outputsMetadata":{"0":{"height":525,"type":"stream"}}},"cell_type":"code","id":"572a21fd-e075-4d1c-82c6-279530c8395f","outputs":[],"execution_count":13},{"source":"### Instructions\n\n- Run the assistant.","metadata":{},"cell_type":"markdown","id":"224a2ec5-5191-4891-8cee-09c683aaa99b"},{"source":"# Run the assistant\n","metadata":{"executionCancelledAt":null,"executionTime":18810,"lastExecutedAt":1718113617398,"lastExecutedByKernel":"c8505c18-120c-427b-bbc3-1c142740848a","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Run the assistant\nrun_aggie()","outputsMetadata":{"0":{"height":525,"type":"stream"}}},"cell_type":"code","id":"644251b4-3623-4104-9ca8-d23a156cc354","outputs":[],"execution_count":14},{"source":"## Task 6: Add Another Message and Run it Again","metadata":{},"cell_type":"markdown","id":"9c054bf7-3313-46b0-8d1a-fc192ee919c7"},{"source":"Since we've gone to the trouble of creating an assistant, we might as well ask more questions.","metadata":{},"cell_type":"markdown","id":"2a363949-87a8-42b9-9e22-0012282985fe"},{"source":"### Instructions\n\n- Create another user message, adding it to the conversation. This time, ask \"How close are we to developing AGI?\". Assign to `msg_how_close_is_agi`.","metadata":{},"cell_type":"markdown","id":"ea8abe76-9422-49c0-ba1b-c24d0028e1ec"},{"source":"# Create another user message, adding it to the conversation. Assign to msg_how_close_is_agi.\n\n\n# See the result\nmsg_how_close_is_agi","metadata":{"executionCancelledAt":null,"executionTime":158,"lastExecutedAt":1718113617557,"lastExecutedByKernel":"c8505c18-120c-427b-bbc3-1c142740848a","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Create another user message, adding it to the conversation. Assign to msg_how_close_is_agi.\nmsg_how_close_is_agi = client.beta.threads.messages.create(\n    thread_id=conversation.id,\n    role=\"user\",\n    content=\"How close are we to developing AGI?\"\n)\n\n# See the results\nmsg_how_close_is_agi"},"cell_type":"code","id":"2cf9ea40-5c90-4a47-a3d5-59e4f3d3fa74","outputs":[],"execution_count":15},{"source":"### Instructions\n\n- Run the assistant again.","metadata":{},"cell_type":"markdown","id":"2096251c-9776-4ba6-a82e-ba455974bcfd"},{"source":"# Run the assistant\n","metadata":{"executionCancelledAt":null,"executionTime":20374,"lastExecutedAt":1718113637931,"lastExecutedByKernel":"c8505c18-120c-427b-bbc3-1c142740848a","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Run the assistant\nrun_aggie()","outputsMetadata":{"0":{"height":525,"type":"stream"}}},"cell_type":"code","id":"39d1173c-a1f5-4ebc-be74-a66fa8b80959","outputs":[],"execution_count":16},{"source":"## Want to learn more?","metadata":{},"cell_type":"markdown","id":"8c3b39c9-1757-4653-8ce0-15212701e505"},{"source":"If you want to learn about developing applications with generative AI, take this DataCamp content. \n\n- [Developing AI Applications](https://www.datacamp.com/tracks/developing-ai-applications) skill track.\n- [Become a Generative AI Developer](https://www.datacamp.com/ai-code-alongs) code-along series.","metadata":{},"cell_type":"markdown","id":"c725f108-9a20-4b18-bbdb-d5a663e8e487"}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":5}